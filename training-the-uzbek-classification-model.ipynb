{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11366332,"sourceType":"datasetVersion","datasetId":7114718}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:22:22.735819Z","iopub.execute_input":"2025-04-11T16:22:22.736318Z","iopub.status.idle":"2025-04-11T16:22:24.983548Z","shell.execute_reply.started":"2025-04-11T16:22:22.736286Z","shell.execute_reply":"2025-04-11T16:22:24.983018Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/uzbek-news-dataset/balanced_news_dataset_100k.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/uzbek-news-dataset/balanced_news_dataset_100k.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:22:24.984061Z","iopub.execute_input":"2025-04-11T16:22:24.984304Z","iopub.status.idle":"2025-04-11T16:23:10.129580Z","shell.execute_reply.started":"2025-04-11T16:22:24.984288Z","shell.execute_reply":"2025-04-11T16:23:10.128843Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text           label\n0  U-Report: O‘zbekistonda yangi innovatsion loyi...  fan va texnika\n1  Bolalikda o‘qilgan fantastik kitoblar yoxud 20...  fan va texnika\n2  Kanadalik erkak 14 yildan buyon o‘yinchoq eksk...  fan va texnika\n3  Samsung Galaxy S21 Ultra eng yaxshi kamerofonl...  fan va texnika\n4  Meizu’ning ilk romsiz smartfoni suratlari payd...  fan va texnika","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U-Report: O‘zbekistonda yangi innovatsion loyi...</td>\n      <td>fan va texnika</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bolalikda o‘qilgan fantastik kitoblar yoxud 20...</td>\n      <td>fan va texnika</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kanadalik erkak 14 yildan buyon o‘yinchoq eksk...</td>\n      <td>fan va texnika</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Samsung Galaxy S21 Ultra eng yaxshi kamerofonl...</td>\n      <td>fan va texnika</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Meizu’ning ilk romsiz smartfoni suratlari payd...</td>\n      <td>fan va texnika</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df.shape, df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:23:10.130363Z","iopub.execute_input":"2025-04-11T16:23:10.130622Z","iopub.status.idle":"2025-04-11T16:23:10.169945Z","shell.execute_reply.started":"2025-04-11T16:23:10.130592Z","shell.execute_reply":"2025-04-11T16:23:10.169292Z"},"_kg_hide-input":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((584276, 2),\n label\n jahon             100000\n jamiyat           100000\n qonunchilik       100000\n o'zbekiston       100000\n sport             100000\n fan va texnika     84276\n Name: count, dtype: int64)"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Preprocessing the data","metadata":{}},{"cell_type":"code","source":"import re\n\ndef preprocess_uzbek(text):\n    text = text.lower()  # lowercase\n    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n    text = text.strip()  # remove leading/trailing spaces\n    text = re.sub(r\"\\s+\", \" \", text)  # replace multiple spaces with single\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:23:10.171970Z","iopub.execute_input":"2025-04-11T16:23:10.172249Z","iopub.status.idle":"2025-04-11T16:23:10.189295Z","shell.execute_reply.started":"2025-04-11T16:23:10.172232Z","shell.execute_reply":"2025-04-11T16:23:10.188763Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df['text'] = df['text'].apply(preprocess_uzbek)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:23:10.189996Z","iopub.execute_input":"2025-04-11T16:23:10.190257Z","iopub.status.idle":"2025-04-11T16:25:02.046169Z","shell.execute_reply.started":"2025-04-11T16:23:10.190235Z","shell.execute_reply":"2025-04-11T16:25:02.045395Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df.tail(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:02.047077Z","iopub.execute_input":"2025-04-11T16:25:02.047344Z","iopub.status.idle":"2025-04-11T16:25:02.054590Z","shell.execute_reply.started":"2025-04-11T16:25:02.047320Z","shell.execute_reply":"2025-04-11T16:25:02.053858Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                     text  label\n584271  18 avgust 2 sentabr kunlari indoneziyaning jak...  sport\n584272  futbol boyicha yevropa chempionatlari tarixida...  sport\n584273  poytaxtimizdagi lotte city hotel tashkent pala...  sport\n584274  video daniyada futbol muxlislari maydonga olik...  sport\n584275  sport fidoyisi koplab chempionlarni tarbiyalag...  sport","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>584271</th>\n      <td>18 avgust 2 sentabr kunlari indoneziyaning jak...</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>584272</th>\n      <td>futbol boyicha yevropa chempionatlari tarixida...</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>584273</th>\n      <td>poytaxtimizdagi lotte city hotel tashkent pala...</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>584274</th>\n      <td>video daniyada futbol muxlislari maydonga olik...</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>584275</th>\n      <td>sport fidoyisi koplab chempionlarni tarbiyalag...</td>\n      <td>sport</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Shuffle the entire dataset\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Check the first few rows after shuffling\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:02.055219Z","iopub.execute_input":"2025-04-11T16:25:02.055452Z","iopub.status.idle":"2025-04-11T16:25:02.394145Z","shell.execute_reply.started":"2025-04-11T16:25:02.055436Z","shell.execute_reply":"2025-04-11T16:25:02.393544Z"}},"outputs":[{"name":"stdout","text":"                                                text           label\n0  oq uyning milliy xavfsizlik masalalari boyicha...           jahon\n1  apple 32 gb xotirali yangi ipad pro planshetin...  fan va texnika\n2  penzada roy bergan dahshatli ythda 4 kishi hal...           jahon\n3  11iyun dunyo okeanlari tadqiqotchisi fransuz d...           jahon\n4  bugun 10 sentyabr kuni ozbekiston respublikasi...         jamiyat\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:02.394849Z","iopub.execute_input":"2025-04-11T16:25:02.395074Z","iopub.status.idle":"2025-04-11T16:25:22.501653Z","shell.execute_reply.started":"2025-04-11T16:25:02.395034Z","shell.execute_reply":"2025-04-11T16:25:22.500905Z"}},"outputs":[{"name":"stderr","text":"2025-04-11 16:25:05.961460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744388706.428572      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744388706.566516      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# # Sample text data\n# sample_texts = ['O\\'zbekiston sport sohasida yirik o\\'zgarishlar yuz berdi.',\n#                 'Jahon yangiliklari va sport musobaqalari haqida ma\\'lumotlar.']\n\n# # Tokenizer instance\n# tokenizer = Tokenizer(num_words=5000)  # Limit vocab size to 5000 words\n# tokenizer.fit_on_texts(sample_texts)  # Fit tokenizer on the sample text data\n\n# # Convert the texts to sequences of integers\n# sequences = tokenizer.texts_to_sequences(sample_texts)\n\n# # Print the result\n# print(f\"Tokenized Sequences: {sequences}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:22.502492Z","iopub.execute_input":"2025-04-11T16:25:22.502875Z","iopub.status.idle":"2025-04-11T16:25:22.506348Z","shell.execute_reply.started":"2025-04-11T16:25:22.502859Z","shell.execute_reply":"2025-04-11T16:25:22.505557Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# # Example tokenized sequences\n# sequences = [[2, 1, 3, 4, 5, 6, 7], [8, 9, 10, 1, 11, 12, 13]]\n\n# # Create the reverse word_index\n# reverse_word_index = {index: word for word, index in tokenizer.word_index.items()}\n\n# # Convert the sequences back to words\n# sequences_as_words = [[reverse_word_index.get(index, '') for index in sequence] for sequence in sequences]\n\n# # Print the tokenized text as words\n# print(sequences_as_words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:22.507186Z","iopub.execute_input":"2025-04-11T16:25:22.507451Z","iopub.status.idle":"2025-04-11T16:25:22.552015Z","shell.execute_reply.started":"2025-04-11T16:25:22.507427Z","shell.execute_reply":"2025-04-11T16:25:22.551518Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"text_lengths = df['text'].apply(lambda x: len(x.split()))\n\n# Check the distribution (mean, max, etc.)\nprint(f\"Mean Length: {text_lengths.mean()}\")\nprint(f\"Max Length: {text_lengths.max()}\")\nprint(f\"Min Length: {text_lengths.min()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:22.552705Z","iopub.execute_input":"2025-04-11T16:25:22.552897Z","iopub.status.idle":"2025-04-11T16:25:31.498703Z","shell.execute_reply.started":"2025-04-11T16:25:22.552880Z","shell.execute_reply":"2025-04-11T16:25:31.498100Z"}},"outputs":[{"name":"stdout","text":"Mean Length: 300.77756916251906\nMax Length: 8012\nMin Length: 0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Assuming 'df' is your DataFrame and 'text' is the column with the text data\ntokenizer = Tokenizer(num_words=5000)  # Limit vocab size to top 5000 words\ntokenizer.fit_on_texts(df['text'])  # Fit tokenizer on the 'text' column\n\n# Convert texts to sequences of integers\nsequences = tokenizer.texts_to_sequences(df['text'])\n\n# Pad sequences to ensure all are the same length\nmax_length = 300  # You can adjust this value based on your data and model requirements\npadded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n\n# View the tokenized and padded sequences\nprint(padded_sequences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:25:31.499358Z","iopub.execute_input":"2025-04-11T16:25:31.499547Z","iopub.status.idle":"2025-04-11T16:28:29.732529Z","shell.execute_reply.started":"2025-04-11T16:25:31.499533Z","shell.execute_reply":"2025-04-11T16:28:29.731779Z"}},"outputs":[{"name":"stdout","text":"[[1316 4330   75 ...    0    0    0]\n [ 824  914 1552 ...    0    0    0]\n [1647  266   99 ...    0    0    0]\n ...\n [ 408 1014 1176 ...    0    0    0]\n [3567 3500 1309 ...    0    0    0]\n [1360 1777   29 ...    0    0    0]]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"df.tail(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:28:29.734906Z","iopub.execute_input":"2025-04-11T16:28:29.735181Z","iopub.status.idle":"2025-04-11T16:28:29.742749Z","shell.execute_reply.started":"2025-04-11T16:28:29.735155Z","shell.execute_reply":"2025-04-11T16:28:29.742039Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                     text        label\n584273  ohangaron tumani 1umumtalim maktabining 11sinf...  o'zbekiston\n584274  yurak kochirish operatsiyasi yanvar oyida meri...        jahon\n584275  shvetsiyalik olimlar tadqiqot otkazishdi u qis...        jahon","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>584273</th>\n      <td>ohangaron tumani 1umumtalim maktabining 11sinf...</td>\n      <td>o'zbekiston</td>\n    </tr>\n    <tr>\n      <th>584274</th>\n      <td>yurak kochirish operatsiyasi yanvar oyida meri...</td>\n      <td>jahon</td>\n    </tr>\n    <tr>\n      <th>584275</th>\n      <td>shvetsiyalik olimlar tadqiqot otkazishdi u qis...</td>\n      <td>jahon</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['label'])  # Replace 'category' with your column name\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:28:29.743683Z","iopub.execute_input":"2025-04-11T16:28:29.743904Z","iopub.status.idle":"2025-04-11T16:28:30.217642Z","shell.execute_reply.started":"2025-04-11T16:28:29.743889Z","shell.execute_reply":"2025-04-11T16:28:30.217094Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:28:30.218328Z","iopub.execute_input":"2025-04-11T16:28:30.218823Z","iopub.status.idle":"2025-04-11T16:28:30.234366Z","shell.execute_reply.started":"2025-04-11T16:28:30.218804Z","shell.execute_reply":"2025-04-11T16:28:30.233721Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"label\n1    100000\n2    100000\n4    100000\n3    100000\n5    100000\n0     84276\nName: count, dtype: int64"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming you have labels in a column named 'label' in your dataframe\nX = padded_sequences  # Features (tokenized and padded text)\ny = df['label'].values  # Labels (your target variable)\n\n# Split the data into training and validation sets (80% train, 20% validation)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n\nprint(f\"Training data shape: {X_train.shape}\")\nprint(f\"Validation data shape: {X_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:28:30.235557Z","iopub.execute_input":"2025-04-11T16:28:30.236029Z","iopub.status.idle":"2025-04-11T16:28:30.732398Z","shell.execute_reply.started":"2025-04-11T16:28:30.236001Z","shell.execute_reply":"2025-04-11T16:28:30.731619Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (525848, 300)\nValidation data shape: (58428, 300)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!pip install --upgrade tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T16:28:30.733240Z","iopub.execute_input":"2025-04-11T16:28:30.733750Z","iopub.status.idle":"2025-04-11T16:29:46.245123Z","shell.execute_reply.started":"2025-04-11T16:28:30.733730Z","shell.execute_reply":"2025-04-11T16:29:46.244180Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nCollecting tensorflow\n  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\nCollecting tensorboard~=2.19.0 (from tensorflow)\n  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\nCollecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.2.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.2.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.2.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.2.0,>=1.26.0->tensorflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.2.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.2.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.2.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.2.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.2.0,>=1.26.0->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.2.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.2.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"y_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:09:14.294457Z","iopub.execute_input":"2025-04-11T17:09:14.295231Z","iopub.status.idle":"2025-04-11T17:09:14.300415Z","shell.execute_reply.started":"2025-04-11T17:09:14.295207Z","shell.execute_reply":"2025-04-11T17:09:14.299691Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([4, 4, 0, ..., 3, 1, 2])"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Model 1","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n\nnum_classes = len(np.unique(y_train))  # Should be 5 in your case\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=5000, output_dim=100, input_length=300))\nmodel.add(LSTM(128, return_sequences=False))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(num_classes, activation='softmax'))  # Use softmax for multi-class\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.build(input_shape=(None, X.shape[1]))\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:12:03.798138Z","iopub.execute_input":"2025-04-11T17:12:03.798477Z","iopub.status.idle":"2025-04-11T17:12:03.865401Z","shell.execute_reply.started":"2025-04-11T17:12:03.798455Z","shell.execute_reply":"2025-04-11T17:12:03.864787Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m500,000\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m117,248\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m618,022\u001b[0m (2.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">618,022</span> (2.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m618,022\u001b[0m (2.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">618,022</span> (2.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# evaluating to see reaction of model to values\nloss, accuracy = model.evaluate(X_train, y_train, verbose=1)\nprint(f\"Initial loss: {loss:.4f}\")\nprint(f\"Initial accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:12:08.664008Z","iopub.execute_input":"2025-04-11T17:12:08.664309Z","iopub.status.idle":"2025-04-11T17:13:35.562306Z","shell.execute_reply.started":"2025-04-11T17:12:08.664290Z","shell.execute_reply":"2025-04-11T17:13:35.561307Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m16433/16433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 5ms/step - accuracy: 0.1767 - loss: 1.7917\nInitial loss: 1.7917\nInitial accuracy: 0.1761\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Train the model\nmodel.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val))\n\n# Evaluate the model on the validation set\nval_loss, val_acc = model.evaluate(X_val, y_val)\nprint(f\"Validation Loss: {val_loss}\")\nprint(f\"Validation Accuracy: {val_acc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:17:22.023215Z","iopub.execute_input":"2025-04-11T17:17:22.023727Z","iopub.status.idle":"2025-04-11T17:28:01.625972Z","shell.execute_reply.started":"2025-04-11T17:17:22.023705Z","shell.execute_reply":"2025-04-11T17:28:01.625361Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 15ms/step - accuracy: 0.5241 - loss: 1.0970 - val_accuracy: 0.8433 - val_loss: 0.4056\nEpoch 2/5\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 15ms/step - accuracy: 0.8556 - loss: 0.3845 - val_accuracy: 0.8753 - val_loss: 0.3267\nEpoch 3/5\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 15ms/step - accuracy: 0.8819 - loss: 0.3109 - val_accuracy: 0.8838 - val_loss: 0.3010\nEpoch 4/5\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 15ms/step - accuracy: 0.8981 - loss: 0.2678 - val_accuracy: 0.8910 - val_loss: 0.2812\nEpoch 5/5\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 15ms/step - accuracy: 0.9126 - loss: 0.2322 - val_accuracy: 0.8957 - val_loss: 0.2697\n\u001b[1m1826/1826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8953 - loss: 0.2698\nValidation Loss: 0.26973193883895874\nValidation Accuracy: 0.8957006931304932\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Model 2","metadata":{}},{"cell_type":"code","source":"model2 = Sequential()\nmodel2.add(Embedding(input_dim=5000, output_dim=100, input_length=300))\nmodel2.add(LSTM(128, return_sequences=False))\nmodel2.add(Dropout(0.4))\nmodel2.add(Dense(64, activation='relu'))\nmodel2.add(Dropout(0.3))\nmodel2.add(Dense(num_classes, activation='softmax'))  # Use softmax for multi-class\n\nmodel2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel2.build(input_shape=(None, X.shape[1]))\nmodel2.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:32:46.700835Z","iopub.execute_input":"2025-04-11T17:32:46.701601Z","iopub.status.idle":"2025-04-11T17:32:46.769684Z","shell.execute_reply.started":"2025-04-11T17:32:46.701577Z","shell.execute_reply":"2025-04-11T17:32:46.769116Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m500,000\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m117,248\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m390\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m625,894\u001b[0m (2.39 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">625,894</span> (2.39 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m625,894\u001b[0m (2.39 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">625,894</span> (2.39 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\nmodel2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=15, batch_size=64, callbacks=[early_stop])\n\nval_loss, val_acc = model2.evaluate(X_val, y_val)\nprint(f\"Validation Loss: {val_loss}\")\nprint(f\"Validation Accuracy: {val_acc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:34:16.796912Z","iopub.execute_input":"2025-04-11T17:34:16.797655Z","iopub.status.idle":"2025-04-11T17:55:52.918194Z","shell.execute_reply.started":"2025-04-11T17:34:16.797630Z","shell.execute_reply":"2025-04-11T17:55:52.917349Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 16ms/step - accuracy: 0.4678 - loss: 1.1861 - val_accuracy: 0.8312 - val_loss: 0.4151\nEpoch 2/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.8528 - loss: 0.3954 - val_accuracy: 0.8752 - val_loss: 0.3222\nEpoch 3/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.8807 - loss: 0.3185 - val_accuracy: 0.8809 - val_loss: 0.3016\nEpoch 4/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.8954 - loss: 0.2786 - val_accuracy: 0.8879 - val_loss: 0.2898\nEpoch 5/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.9072 - loss: 0.2472 - val_accuracy: 0.8915 - val_loss: 0.2818\nEpoch 6/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.9190 - loss: 0.2184 - val_accuracy: 0.8967 - val_loss: 0.2778\nEpoch 7/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.9288 - loss: 0.1944 - val_accuracy: 0.9000 - val_loss: 0.2723\nEpoch 8/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.9389 - loss: 0.1700 - val_accuracy: 0.9035 - val_loss: 0.2689\nEpoch 9/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.9475 - loss: 0.1500 - val_accuracy: 0.9042 - val_loss: 0.2785\nEpoch 10/15\n\u001b[1m8217/8217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - accuracy: 0.9541 - loss: 0.1331 - val_accuracy: 0.9054 - val_loss: 0.2771\n\u001b[1m1826/1826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.2709\nValidation Loss: 0.2689213156700134\nValidation Accuracy: 0.9035223126411438\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Save the model to a file (in H5 format)\nmodel2.save('uzbek_news_classification_model.h5')  # Replace 'your_model_name.h5' with your preferred file name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:06:04.533576Z","iopub.execute_input":"2025-04-11T18:06:04.533861Z","iopub.status.idle":"2025-04-11T18:06:04.598481Z","shell.execute_reply.started":"2025-04-11T18:06:04.533843Z","shell.execute_reply":"2025-04-11T18:06:04.597647Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# import numpy as np\n# from tensorflow.keras.preprocessing.text import Tokenizer\n# from tensorflow.keras.preprocessing.sequence import pad_sequences\n# from tensorflow.keras.models import load_model\n# import re\n\n# # # Load the trained model\n# # model2 = load_model('your_model_name.h5')\n\n# # Assume you have a function to clean the text (you can define your own cleaning logic)\n# def clean_text(text):\n#     # Example cleaning logic (remove punctuation, lowercase, etc.)\n#     text = text.lower()  # lowercase\n#     text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n#     text = text.strip()  # remove leading/trailing spaces\n#     text = re.sub(r\"\\s+\", \" \", text)  # replace multiple spaces with single\n#     return text\n\n# # New text to test\n# new_text = (\"«Tog‘ oldi va tog‘li hududlarda istiqomat qiluvchi fuqarolarni, dam oluvchilarni hamda tog‘li hududlarda harakatlanuvchi haydovchilarni ehtiyotkorlik choralarini ko‘rishlarini so‘raymiz. Respublika hududi bo‘yicha yomg‘ir suvlari to‘planishi ehtimoli bor, bu esa hududlarni suv bosishiga olib kelishi mumkin», — deyiladi xabarda.\")\n\n\n# # Clean the new text\n# cleaned_text = clean_text(new_text)\n\n# # Tokenize and pad the new text (same as how you preprocessed the training data)\n# tokenizer = Tokenizer(num_words=5000)\n# tokenizer.fit_on_texts([cleaned_text])  # Fit on the new text (or you could use the same tokenizer from training)\n# sequence = tokenizer.texts_to_sequences([cleaned_text])\n# padded_sequence = pad_sequences(sequence, maxlen=300, padding='post', truncating='post')\n\n# # Make prediction with the model\n# prediction = model2.predict(padded_sequence)\n\n# # Print prediction (for multi-class, we will use argmax to get the class with the highest probability)\n# predicted_class = np.argmax(prediction, axis=1)\n\n# print(f\"Predicted class: {predicted_class[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:33:59.932414Z","iopub.execute_input":"2025-04-11T18:33:59.933026Z","iopub.status.idle":"2025-04-11T18:34:00.010428Z","shell.execute_reply.started":"2025-04-11T18:33:59.933006Z","shell.execute_reply":"2025-04-11T18:34:00.009873Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\nPredicted class: 4\n","output_type":"stream"}],"execution_count":51}]}